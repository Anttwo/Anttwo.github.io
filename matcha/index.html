<!DOCTYPE html>
<html lang="en">
<head>
 <title>MAtCha</title>
 <meta name="description" content="MAtCha Gaussians: Atlas of Charts for High-Quality Geometry and Photorealism From Sparse Views"/>
 <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=yes">
 <meta charset="utf-8">
 <!-- <link rel="icon" href="./icon_unicorn.png" type="image/png"> -->

 <!--Facebook-->
 <meta property="og:image" content="">
 <meta property="og:image:type" content="image/jpg">
 <meta property="og:image:width" content="600">
 <meta property="og:image:height" content="400">
 <meta property="og:type" content="website"/>
 <meta property="og:url" content="https://anttwo.github.io/matcha/"/>
 <meta property="og:title" content="MAtCha"/>
 <meta property="og:description" content="Project page for MAtCha Gaussians: Atlas of Charts for High-Quality Geometry and Photorealism From Sparse Views"/>

 <!--Twitter-->
 <meta name="twitter:card" content="summary_large_image" />
 <meta name="twitter:title" content="MAtCha" />
 <meta property="twitter:description" content="MAtCha Gaussians: Atlas of Charts for High-Quality Geometry and Photorealism From Sparse Views."/>
 <meta name="twitter:image" content="">

 <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
 <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
 <!-- <link href="https://fonts.googleapis.com/css?family=Montserrat:800|Roboto:400,700" rel="stylesheet"> -->
 <link rel="preconnect" href="https://fonts.googleapis.com">
 <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin> 
 <link href="https://fonts.googleapis.com/css2?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" rel="stylesheet"> 
 <!-- <link href="http://fonts.googleapis.com/css?family=Roboto:ital,wght@0,100;0,300;0,400;0,500;0,700;0,900;1,100;1,300;1,400;1,500;1,700;1,900&display=swap" rel="stylesheet">  -->
 
 <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
 <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>

 <!-- <link href="style_2.css" rel="stylesheet"> -->
 <!-- <link href="style.css" rel="stylesheet"> -->
 <link href="../base2.css" rel="stylesheet">

<!--  Google Analytics (DO NOT copy/paste following section, setup your own analytics tag at https://analytics.google.com/analytics/web/)  -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-CDL4R10HKE"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-CDL4R10HKE');
</script>
<!-- End Google Analytics -->

<link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
<link href="https://fonts.googleapis.com/icon?family=Material+Icons+Outlined" rel="stylesheet">

</head>
<body>

<div class="container" style="text-align:center; padding-top:2rem 15px">
 <div class="row" style="text-align:center">
   <h1 style="font-size: 60px;">MAtCha Gaussians: <br>Atlas of Charts for High-Quality Geometry and Photorealism From Sparse Views</h1>
   <h1 style="font-size: xxx-large;">arXiv 2024</h1>
 </div>
 <div class="row" style="text-align:center">
   <div class="col-xs-0 col-md-2"></div>
   <div class="col-xs-12 col-md-8">
     <h4 style="font-size: 22px;">
       <nobr><a href="https://anttwo.github.io/">Antoine Gu&eacutedon<sup>1</sup></a></nobr> &emsp;
       <nobr><a href="https://scholar.google.com/citations?user=-LzEJVwAAAAJ&hl=en">Tomoki Ichikawa<sup>2</sup></a></nobr> &emsp;
       <nobr><a href="https://kyamashita5.github.io/">Kohei Yamashita<sup>2</sup></a></nobr> &emsp;
       <nobr><a href="https://scholar.google.com/citations?user=SXXEZhYAAAAJ&hl=en">Ko Nishino<sup>2</sup></a></nobr>
     </h4>
     <p style="font-size: 20px; text-align: center;"><nobr><sup>1</sup>LIGM, Ecole des Ponts</nobr>, <nobr>Univ Gustave Eiffel</nobr>, CNRS</nobr>, France<br></p>
     <p style="font-size: 20px; text-align: center;"><nobr><sup>2</sup>Graduate School of Informatics</nobr>, Kyoto University</nobr>, Japan<br></p>
   </div>
   <!-- <div class="hidden-xs hidden-sm col-md-1" style="text-align:left; margin-left:0px; margin-right:0px">
     <a href="https://arxiv.org/abs/2303.03315" style="color:#448D87">
       <i class="fa fa-file-pdf-o fa-4x"></i></a>
   </div>
   <div class="hidden-xs hidden-sm col-md-1" style="text-align:left; margin-left:0px;">
     <a href="https://github.com/Anttwo/SuGaR" style="color:#448D87">
       <i class="fa fa-github fa-4x"></i></a>
   </div> -->
 </div>
</div>

<div class="container" style="text-align:center; padding:0rem">
 <div class="row">
   <div class="col-xs-12">
   <h3 style="text-align:center; padding-bottom:1rem">
     <a class="label label-info" href="https://arxiv.org/"><i class="fa fa-file-text"></i>&nbsp;&nbsp;Paper</a>
     <a class="label label-info" href="https://github.com/Anttwo/MAtCha"><i class="fa fa-code fa-lg" style="vertical-align: top; margin-top: 6px"></i>&nbsp;&nbsp;Code (Coming Soon)</a>
     <!-- <a class="label label-info" href="https://github.com/Anttwo/sugar_frosting_blender_addon/"><i class="fa fa-gamepad fa-lg" style="vertical-align:top; margin-top:5px"></i>&nbsp;&nbsp;Blender Add-On</a> -->
     <a class="label label-info" href="./ref.bib"><i class="fa fa-commenting fa-lg" style="vertical-align:top;margin-top:6px"></i>&nbsp;&nbsp;BibTeX</a>
   </h3>
   </div>
 </div>

 <div class="row" style="padding:2rem">
   <div class="col-xs-12">
   <!-- <video autoplay loop muted playsinline src="teaser.mp4" style="width:95%; max-width: 900px"></video> -->
   <!-- <iframe class="embed-responsive-item text-center" src="https://www.youtube.com/embed/MAkFyWfiBQo?si=mIN-4Wk3P2sWBG7C" frameborder="0"
          allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
          style="width:100%; height:540px; clip-path:inset(1px 1px);" allowfullscreen></iframe> -->
  <!-- <iframe src="https://drive.google.com/file/d/1oov9S0Cw0LKr31M-bWpr1JAdG-fG49Er/preview"
     width=100% height="620px" frameborder="0" allow="autoplay" allowfullscreen></iframe> -->
  <iframe class="embed-responsive-item text-center" src="https://drive.google.com/file/d/1eisdCFnWs8cAI8flOJ93ZQ8tkqSZmcEB/preview" frameborder="0"
     allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
     style="width:100%; height:620px; clip-path:inset(1px 1px);" allowfullscreen></iframe>
  <!-- <i><b>The full presentation video is coming soon.</b></i> -->
   <div class="wrapper">
     <!-- <div class="col-xs-4 col-lg-6;"> -->
      <p style="text-align: justify">
        <br> We propose <b>MAtCha Gaussians</b>, a novel surface representation for <b>reconstructing 
        high-quality 3D meshes with photorealistic rendering from sparse-view images</b>.
        Our key idea is to model the underlying scene geometry as an <b>Atlas of Charts</b> which we render with 2D 
        <b>Gaussian surfels</b>.
        We initialize the charts with a <b>monocular depth estimation model</b> and refine them using 
        <b>differentiable Gaussian rendering</b> and a <b>lightweight neural chart deformation model</b>.
        Combined with a sparse-view SfM model like 
        <a href="https://europe.naverlabs.com/research/publications/mast3r-sfm-a-fully-integrated-solution-for-unconstrained-structure-from-motion/">MASt3R-SfM</a>, 
        MAtCha can recover <b>sharp and accurate surface meshes</b> 
        of both <b>foreground and background objects</b> in <b>unbounded scenes</b> within minutes, only from 
        <b>a few unposed RGB images</b>. 
      </p>
     <!-- </div> -->
   </div>
   </div>
 </div>
</div>

<div class="container">
  <h2>Updates</h2>
  <hr/>
  <p>
    <ul>
      <li> <b>12-2024</b>: Initial release of the paper. </li>
    </ul>
  </p>
<!-- </div> -->
<p><br></p>

<!-- <div class="container"> -->
 <h2>Overview</h2>
 <hr/>
 <!-- <p>
  TODO: Add some results here.
 </p> -->
 
 <p>
    We present a novel appearance model that simultaneously realizes explicit <b>high-quality 3D surface mesh recovery</b> 
    and <b>photorealistic novel view synthesis</b> from <b>sparse view samples</b>. <br><br>

    Our key idea is to model the underlying scene geometry <b>M</b>esh as an <b>At</b>las of <b>Cha</b>rts 
    which we render with 2D <b>Gaussian</b> surfels (MAtCha Gaussians).<br><br>

    MAtCha distills <b>high-frequency scene surface details</b> from an off-the-shelf <b>monocular depth estimator</b> 
    and refines it through <a href="https://surfsplatting.github.io/">2D Gaussian surfel rendering</a>.     
    The Gaussian surfels are attached to the charts on the fly, satisfying photorealism of neural volumetric rendering 
    and crisp geometry of a mesh model, <i>i.e.</i>, two seemingly contradicting goals in a single model. <br><br>
    
    At the core of MAtCha lies a <b>novel neural deformation model</b> and a <b>structure loss</b> that preserve the fine surface details 
    distilled from learned monocular depths while addressing their fundamental scale ambiguities. <br><br>

    Results of extensive experimental validation demonstrate MAtCha's state-of-the-art quality of surface reconstruction 
    and photorealism on-par with top contenders but with dramatic reduction in the number of input views and computational time.<br>
    
    We believe MAtCha will serve as a foundational tool for any visual application in vision, graphics, 
    and robotics that require explicit geometry in addition to photorealism. 
 </p>
<!-- </div> -->

 <p><br></p>

 <h2>Optimizing Charts in a Sparse-View Scenario</h2>
 <hr/>

 <p>
  Given a few RGB images and their camera poses obtained using a sparse-view SfM method such as 
  <a href="https://europe.naverlabs.com/research/publications/mast3r-sfm-a-fully-integrated-solution-for-unconstrained-structure-from-motion/">MASt3R-SfM</a>, 
  we first initialize charts using a 
  <a href="https://depth-anything-v2.github.io/">pretrained monocular depth estimation model</a>. 
  Each chart is represented as a mesh equipped with a UV map, mapping a 2D plane to the 3D surface.
 </p>
 <div class="col-xs-4 col-lg-12" style="text-align:center">
  <!-- <img src="https://anttwo.github.io/matcha/images/pipeline/pipeline.png" -->
  <img src="./images/pipeline/pipeline.png" 
  alt="pipeline.png" class="text-center" style="width: 85%; max-width: 1920px">
  <br><br>
 </div>
 <p>
    We then optimize our charts and enforce their alignment with input SfM data using three key components: 
    <!-- Bullet points with enumerate -->
    <ul>
      <li> <b>Depth encodings</b> stored along a 1D axis for encouraging points with similar initial depth to be deformed together.</li>
      <li> <b>Charts encodings</b> stored in a sparse 2D grid in UV space for efficiently deforming the geometry 
        while preserving high-frequency surface details visible in the initial depth maps.</li>
      <li> <b>Confidence maps</b> for each chart, for automatically identifying outliers in the input SfM data.</li>
    </ul>
    Both depth and charts encodings are fed into a <b>tiny MLP</b> that outputs a <b>deformation field</b> for each chart. 
    We encourage the deformation field to not only <b>align the charts with the input SfM data</b>, but also to 
    create a <b>coherent manifold structure</b> where charts are aligned with each other.<br><br>

    Our aligned charts provide a sharp, dense and accurate estimate of the 3D scene, 
    which can be further <b>refined</b> using input images and a <b><a href="https://surfsplatting.github.io/">Gaussian Splatting</a>-based rendering pipeline</b>. 
    
    Our representation allows for reconstructing high-quality surface meshes within minutes, even in sparse-view scenarios.
 </p>
 
 <h2>Extracting Meshes from MAtCha Gaussians</h2>
 <hr/>
 <div class="row" style="text-align:center">
  <div class="col-xs-4 col-lg-6">
    <!-- <img src="https://anttwo.github.io/matcha/images/mesh_extraction/tsdf_multires.png"  -->
    <img src="./images/mesh_extraction/tsdf_multires.png"
    alt="tsdf_multires.png" class="text-center" style="width: 100%; max-width: 1000px">
    <br><br>
    <img src="./images/mesh_extraction/tsdf_multires2.png"
    alt="tsdf_multires2.png" class="text-center" style="width: 100%; max-width: 1000px">
   <p style="text-align:center">(a) Multi-resolution TSDF fusion (10 training views)</p>
 </div>
 <div class="col-xs-4 col-lg-6">
  <!-- <img src="https://anttwo.github.io/matcha/images/mesh_extraction/adaptive_tetra.png"  -->
  <img src="./images/mesh_extraction/adaptive_tetra.png"
  alt="adaptive_tetra.png" class="text-center" style="width: 100%; max-width: 1000px">
  <br><br>
  <img src="./images/mesh_extraction/adaptive_tetra2.png"
  alt="adaptive_tetra2.png" class="text-center" style="width: 100%; max-width: 1000px">
 <p style="text-align:center">(b) Adaptive tetrahedralization (10 training views)</p>
</div>
</div>
<br>

 <p>
  Most existing methods relying on 3D Gaussians or <a href="https://surfsplatting.github.io/">2D Gaussian Surfels</a> 
  apply TSDF fusion on rendered depth maps to extract a mesh from the volumetric representation.
  However, TSDF fusion is limited to bounded scenes and does not allow for extracting high-quality meshes 
  including both foreground and background objects of the scene. 
  Moreover, applying TSDF fusion on 2D Gaussian Surfels can over-smooth the geometry, erode fine details, 
  and produce artifacts, such as <i>"disk-aliasing"</i> patterns on the surface.<br><br>

  In this regard, while we propose a custom multi-resolution TSDF fusion including foreground and background objects in our implementation, 
  we also propose to adapt the tetrahedralization from 
  <a href="https://niujinshuchong.github.io/gaussian-opacity-fields/">Gaussian Opacity Fields (GOF)</a> 
  to make it compatible with any Gaussian-based method capable of rendering perspective-accurate depth maps.
  To this end, for any set of input depth maps, we define a binary opacity field from the depth maps as well as an adaptive dilation operation 
  to avoid eroding geometry during mesh extraction. 
  Because we noticed that the tetrahedralization generally produces meshes with more than 10M vertices, we also modified the implementation 
  to allow users to choose the resolution of the mesh.<br><br>

  We believe that our adaptation of GOF tetrahedralization could provide a high-quality alternative to TSDF fusion for most Gaussian-based surface reconstruction methods.
 </p>

 <!-- <h2>Placeholder</h2>
 <hr/>
 <p>
  To do.
 </p>

 <h2>Scene composition</h2>
 <hr/>
 <h4 width=100% class="highlight" style="padding:0.5em;text-align:center"><b>Example 1: Buzz riding a giant kitten</b></h4>
 <div class="row" style="text-align:center">
  <div class="col-xs-4 col-lg-4" style="transform: translateY(-48px);">
    <iframe class="embed-responsive-item text-center" 
     src="https://drive.google.com/file/d/1kCkjtIfzGb5ZkbeX6LDJm5LCwORHhBF7/preview" 
     frameborder="0"
     allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
     style="width:100%; height:255px; clip-path:inset(48px 1px 1px 1px);" allowfullscreen></iframe>
    <p style="text-align:center">(a) Scene 1: Bicycle</p>
  </div>
  <div class="col-xs-4 col-lg-4" style="transform: translateY(-48px);">
    <iframe src="https://drive.google.com/file/d/1XSlVnRxL9y7NfRxK7zr3-YK6rRBnf7hU/preview"
    frameborder="0"
    allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
    style="width:100%; height:255px; clip-path:inset(48px 1px 1px 1px);" allowfullscreen></iframe>
    <p style="text-align:center">(b) Scene 2: Buzz</p>
  </div>
  <div class="col-xs-4 col-lg-4" style="transform: translateY(-48px);">
    <iframe src="https://drive.google.com/file/d/1bFI6kUoMkoPl126aSGLOYU4tkXIVUT42/preview"
    frameborder="0"
     allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
     style="width:100%; height:255px; clip-path:inset(48px 1px 1px 1px);" allowfullscreen></iframe>
    <p style="text-align:center">(c) Scene 3: Kitten</p>
  </div>
</div>
<div class="row" style="text-align:center">
  <div class="col-xs-4 col-lg-6">
    <img src="https://anttwo.github.io/frosting/results/composition/buzz_riding_cat/mesh.png" 
    alt="buzz_kitten_composition.png" class="text-center" style="width: 100%; max-width: 1000px">
   <p style="text-align:center">(d) Posing meshes</p>
 </div>
  <div class="col-xs-4 col-lg-6">
    <iframe src="https://drive.google.com/file/d/1viJZaWVve2t48R5v_yQAQn3nQGtqfXph/preview"
     width=100% height="310px" frameborder="0" allow="autoplay" allowfullscreen></iframe>
    <p style="text-align:center">(e) Rendering composition</p>
  </div>
</div>
<br>
<p>
  In the example above, we were able to animate both Buzz and the kitten, changing their original pose (d) while preserving 
  high-quality rendering (e). Contrary to <a href="https://anttwo.github.io/sugar">SuGaR</a> (g), very fine and fuzzy details such as the
  kitten's hair can be seen covering Buzz's legs in a realistic way (f):
</p>
<div class="row" style="text-align:center">
  <div class="col-xs-4 col-lg-3">
    <img src="https://anttwo.github.io/frosting/results/composition/buzz_riding_cat/closeup_1.png" 
    alt="gt_detail.png" class="text-center" style="width: 100%; max-width: 1000px">
  </div>
  <div class="col-xs-4 col-lg-3">
   <img src="https://anttwo.github.io/frosting/results/composition/buzz_riding_cat/closeup_2.png" 
   alt="3dgs_detail.png" class="text-center" style="width: 100%; max-width: 1000px">
 </div>
 <div class="col-xs-4 col-lg-3">
  <img src="https://anttwo.github.io/frosting/results/composition/buzz_riding_cat/closeup_1_flat.png" 
  alt="gt_detail.png" class="text-center" style="width: 100%; max-width: 1000px">
</div>
<div class="col-xs-4 col-lg-3">
 <img src="https://anttwo.github.io/frosting/results/composition/buzz_riding_cat/closeup_2_flat.png" 
 alt="3dgs_detail.png" class="text-center" style="width: 100%; max-width: 1000px">
</div>
</div>
<div class="row" style="text-align:center">
  <div class="col-xs-4 col-lg-6">
    <p style="text-align:center">(f) Fuzzy details with Frosting - occlusions are correctly rendered</p>
  </div>
  <div class="col-xs-4 col-lg-6">
   <p style="text-align:center">(g)  Rendering with <a href="https://anttwo.github.io/sugar">SuGaR</a> - the fur does not occlude the legs correctly</p>
 </div>
</div>

<br>

<h4 width=100% class="highlight" style="padding:0.5em;text-align:center"><b>Example 2: Knight resting in the forest</b></h4>
<div class="row" style="text-align:center">
  <div class="col-xs-4 col-lg-4" style="transform: translateY(-48px);">
    <iframe src="https://drive.google.com/file/d/15GBYgTNAeDo7MWdKLDpYG3mbjND4t2qn/preview"
    frameborder="0"
    allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
    style="width:100%; height:255px; clip-path:inset(48px 1px 1px 1px);" allowfullscreen></iframe>
    <p style="text-align:center">(a) Scene 1: Stump</p>
  </div>
  <div class="col-xs-4 col-lg-4" style="transform: translateY(-48px);">
    <iframe src="https://drive.google.com/file/d/1aGtn2KiNAcwt-lgf92VPx5CA97ubCAu-/preview"
    frameborder="0"
    allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
    style="width:100%; height:255px; clip-path:inset(48px 1px 1px 1px);" allowfullscreen></iframe>
    <p style="text-align:center">(b) Scene 2: Knight</p>
  </div>
  <div class="col-xs-4 col-lg-4" style="transform: translateY(-48px);">
    <iframe src="https://drive.google.com/file/d/1jFzHRa2HvGi4G_3jgxFANlJirSoohA8A/preview"
    frameborder="0"
    allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture"
    style="width:100%; height:255px; clip-path:inset(48px 1px 1px 1px);" allowfullscreen></iframe>
    <p style="text-align:center">(c) Scene 3: Horse</p>
  </div>
</div>
<div class="row" style="text-align:center">
  <div class="col-xs-4 col-lg-6">
    <img src="https://anttwo.github.io/frosting/results/composition/knight_and_horse/mesh.png" 
    alt="knight_horse_composition.png" class="text-center" style="width: 100%; max-width: 1000px">
   <p style="text-align:center">(d) Posing meshes</p>
 </div>
  <div class="col-xs-4 col-lg-6">
    <iframe src="https://drive.google.com/file/d/1L12ozu4drFFNWQURo_vIThybckQL7g17/preview"
     width=100% height="310px" frameborder="0" allow="autoplay" allowfullscreen></iframe>
    <p style="text-align:center">(e) Rendering composition</p>
  </div>
</div>

<p><br></p>

 <h2>Animation</h2>
 <hr/>
 <div class="row" style="text-align:center">
  <div class="col-xs-4 col-lg-6">
    <iframe src="https://drive.google.com/file/d/1MiyyvvMsluCwgw13JcEWOTJ0f7V97K6g/preview"
     width=100% height="310px" frameborder="0" allow="autoplay" allowfullscreen></iframe>
    <p style="text-align:center">(a) A knight practicing fencing </p>
  </div>
  <div class="col-xs-4 col-lg-6">
    <iframe src="https://drive.google.com/file/d/1YoQb-jZrkyUzx7L5IQi9DL0EABI0_1Ro/preview"
     width=100% height="310px" frameborder="0" allow="autoplay" allowfullscreen></iframe>
    <p style="text-align:center">(b) Buzz dancing on a bench</p>
  </div>
</div>

<p><br></p>

 <h2>Reconstructing complex scenes with fuzzy materials</h2>
 <hr/>
<div class="row" style="text-align:center">
  <div class="col-xs-4 col-lg-6">
    <iframe src="https://drive.google.com/file/d/1Ioe-wJhS5n46hvpdKk42og2gP15Ir31d/preview"
     width=100% height="310px" frameborder="0" allow="autoplay" allowfullscreen></iframe>
    <p style="text-align:center">(a) Rendering</p>
  </div>
  <div class="col-xs-4 col-lg-6">
    <img src="https://anttwo.github.io/frosting/results/normals/sirius1_normals_52_bis.png" 
    alt="sleepycat_normals.png" class="text-center" style="width: 100%; max-width: 1000px">
   <p style="text-align:center">(b) Normals</p>
 </div>
</div>

<br>

<p>
  Frosting reaches better rendering performance than other editable radiance field methods, 
  and obtains competitive results compared to vanilla 3D Gaussian Splatting. 
  Frosting is even able to outperform vanilla 3DGS when reconstructing scenes with many fuzzy materials,
  such as the scenes from the <a href="https://research.nvidia.com/labs/toronto-ai/adaptive-shells/">Shelly dataset</a>.
</p>

 <div class="row" style="text-align:center">
  <div class="col-xs-4 col-lg-4">
    <img src="https://anttwo.github.io/frosting/results/closeup/khady_gt_22_detail.png" 
    alt="gt_detail.png" class="text-center" style="width: 100%; max-width: 1000px">
    <p style="text-align:center">(c) Ground Truth</p>
  </div>
  <div class="col-xs-4 col-lg-4">
   <img src="https://anttwo.github.io/frosting/results/closeup/khady_3dgs_22_detail.png" 
   alt="3dgs_detail.png" class="text-center" style="width: 100%; max-width: 1000px">
   <p style="text-align:center">(d) 3D Gaussian Splatting</p>
 </div>
 <div class="col-xs-4 col-lg-4">
   <img src="https://anttwo.github.io/frosting/results/closeup/khady_rgb_22_detail.png" 
   alt="frosting_detail.png" class="text-center" style="width: 100%; max-width: 1000px">
   <p style="text-align:center">(e) Frosting (Ours)</p>
 </div>
</div>

<p><br></p>

 <h2>Gaussian <b style="color:#448D87">Frosting</b>: Overview
 </h2>
 <hr/>

   <div class="row" style="text-align:center">
    <div class="hidden-xs col-md-1"></div>
    <div class="col-xs-12 col-md-10">
      <h4 width=100% class="highlight" style="padding:0.5em"><b>1. Forward Process: From Volume to Surface</b></h4>
       <div class="row" style="text-align:center">
       <div class="col-xs-4 col-lg-3">
         <img src="https://anttwo.github.io/frosting/results/meshes/khady_sugar.png" 
         alt="khady_mesh.png" class="text-center" style="width: 100%; max-width: 1000px">
       </div>
       <div class="col-xs-4 col-lg-3">
        <img src="https://anttwo.github.io/frosting/results/meshes/pug_sugar.png" 
        alt="pug_mesh.png" class="text-center" style="width: 100%; max-width: 1000px">
      </div>
      <div class="col-xs-4 col-lg-3">
        <img src="https://anttwo.github.io/frosting/results/meshes/horse_y_sugar.png" 
        alt="horse_mesh.png" class="text-center" style="width: 100%; max-width: 1000px">
      </div>
      <div class="col-xs-4 col-lg-3">
        <img src="https://anttwo.github.io/frosting/results/meshes/kitten_sugar.png" 
        alt="kitten_mesh.png" class="text-center" style="width: 100%; max-width: 1000px">
      </div>
     </div>
     <div>(a) Using the predefined, large parameter D as in <a href="https://anttwo.github.io/sugar">SuGaR</a></div>
     <div class="row" style="text-align:center">
      <div class="col-xs-4 col-lg-3">
        <img src="https://anttwo.github.io/frosting/results/meshes/khady_frosting.png" 
        alt="khady_mesh.png" class="text-center" style="width: 100%; max-width: 1000px">
      </div>
      <div class="col-xs-4 col-lg-3">
       <img src="https://anttwo.github.io/frosting/results/meshes/pug_frosting.png" 
       alt="pug_mesh.png" class="text-center" style="width: 100%; max-width: 1000px">
     </div>
     <div class="col-xs-4 col-lg-3">
       <img src="https://anttwo.github.io/frosting/results/meshes/horse_y_frosting.png" 
       alt="horse_mesh.png" class="text-center" style="width: 100%; max-width: 1000px">
     </div>
     <div class="col-xs-4 col-lg-3">
       <img src="https://anttwo.github.io/frosting/results/meshes/kitten_frosting.png" 
       alt="kitten_mesh.png" class="text-center" style="width: 100%; max-width: 1000px">
     </div>
    </div>
    <div>(b) Using our automatically computed D that adapts to the complexity of the 3DGS</div>
      <p></p><br>
      <p>      
        We start by optimizing a 3D Gaussian Splatting reconstruction for a short period of time and we 
        extract an editable surface mesh with optimal resolution. 
        We improve the surface reconstruction from <a href="https://anttwo.github.io/sugar">SuGaR</a> by automatically estimating a good value for a critical 
        hyperparameter used by Poisson reconstruction, namely the octree depth D.
        Selecting the right value for D can drastically improve both the quality of the mesh and the rendering performance of
        our model.
        </ol>
      </p>
    </div>
    <div class="hidden-xs col-md-1"></div>
  </div>

 <div class="row" style="text-align:center">
   <div class="hidden-xs col-md-1"></div>
   <div class="col-xs-12 col-md-10">
     <h4 width=100% class="highlight" style="padding:0.5em"><b>2. Backward Process: From Surface to Volume</b></h4>
      <div class="row" style="text-align:center">
      <div class="col-xs-4 col-lg-6">
        <img src="https://anttwo.github.io/frosting/results/layer/panda1_rgb_166.png" 
        alt="panda_rgb.png" class="text-center" style="width: 100%; max-width: 1000px">
        <p style="text-align:center">(a) Rendering</p>
      </div>
      <div class="col-xs-4 col-lg-6">
        <img src="https://anttwo.github.io/frosting/results/layer/panda1_size_166.png" 
        alt="panda_thickness.png" class="text-center" style="width: 100%; max-width: 1000px">
        <p style="text-align:center">(b) Thickness of the Frosting layer</p>
      </div>
    </div>
     <p></p>
     <p>      
      After extracting a base mesh, we build a Frosting layer with a variable thickness 
      and containing Gaussians around this mesh. We want this layer to be thicker
      in areas where more volumetric rendering is necessary near the surface, such as
      fuzzy material like hair or grass for example. On the contrary, this layer should
      be very thin near the parts of the scene that corresponds to well-defined flat
      surfaces, such as wood or plastic for example.
       </ol>
     </p>
   </div>
   <div class="hidden-xs col-md-1"></div>
 </div>

 <div class="row" style="text-align:center">
    <div class="hidden-xs col-md-1"></div>
    <div class="col-xs-12 col-md-10">
      <h4 width=100% class="highlight" style="padding:0.5em"><b>3. Frosting optimization and edition</b></h4>
      <div class="row" style="text-align:center">
        <div class="col-xs-4 col-lg-6">
          <img src="https://anttwo.github.io/frosting/results/edition/faraam0_rgb_166.png" 
          alt="original_pose.png" class="text-center" style="width: 100%; max-width: 1000px">
          <p style="text-align:center">(a) Original pose</p>
        </div>
        <div class="col-xs-4 col-lg-6">
          <img src="https://anttwo.github.io/frosting/results/edition/faraam0_rgb_64.png" 
          alt="edited_pose.png" class="text-center" style="width: 100%; max-width: 1000px">
          <p style="text-align:center">(b) Edited pose</p>
        </div>
      </div>
      <p></p>
      <p>
        Once we constructed the Frosting layer, we initialize a densified set of Gaussians 
        inside this layer and optimize them using 3DGS rendering loss. 
        To make sure the Gaussians stay inside the frosting layer during optimization, 
        we introduce a new parameterization of the Gaussians. 
        This parameterization also allows for easily adjusting the Gaussians' parameters 
        when editing the scene and animating characters.
      </p>
    </div>
    <div class="hidden-xs col-md-1"></div>
  </div>

  <p><br></p> -->

 <h2>BibTex</h2>
 <hr/>
 If you find this work useful for your research, please cite:
 <br><br>

 <div class="card">
   <div class="card-block">
     <pre class="card-text clickselect">
      <!-- @article{guedon2024frosting,
        title={Gaussian Frosting: Editable Complex Radiance Fields with Real-Time Rendering},
        author={Gu{\'e}don, Antoine and Lepetit, Vincent},
        journal={ECCV},
        year={2024}
      } -->
      To do.
    </pre>
   </div>
 </div>

 <p><br></p>

 <h2>Further information</h2>
 <hr/>
 If you like this project, check out our previous works related to 3D reconstruction and differentiable rendering:
 <ul>
    <li>
      <a href="https://anttwo.github.io/frosting/">Gu&eacutedon and Lepetit. - 
        Gaussian Frosting: Editable Complex Radiance Fields with Real-Time Rendering
        (ECCV 2024 - Oral)</a>
    </li>
   <li>
    <a href="https://anttwo.github.io/sugar/">Gu&eacutedon and Lepetit. - 
      SuGaR: Surface-Aligned Gaussian Splatting for Efficient 3D Mesh Reconstruction and High-Quality Mesh Rendering
      (CVPR 2024)</a>
   </li>
 </ul>

 <p><br></p>

 <h2>Acknowledgements</h2>
 <hr/>
 <p>
  This work was in part supported by 
  <b>JSPS 20H05951</b> and <b>21H04893</b>, 
  and <b>JST JPMJCR20G7</b> and <b>JPMJAP2305</b>. <br>
  
  This work was also in part supported by the <b>ERC grant "explorer" (No. 101097259)</b>.<br>
  
  This work was granted access to the HPC resources of <b>IDRIS</b> under the allocation 
  <b>2024-AD011013387R2</b> made by <b>GENCI</b>.
 </p>
</div>

<div class="container" style="padding-top:3rem; padding-bottom:3rem">
 <p style="text-align:center">
   &#169; You are welcome to copy the code of the webpage, please attribute the source with a link
   back to this page and remove the analytics.<br>
 </p>
</div>

<!-- Dark mode toggle -->
<script>
  const themeToggle = document.createElement('button');
  themeToggle.className = 'theme-toggle';
  themeToggle.innerHTML = '<span class="material-icons-outlined">dark_mode</span>';

  themeToggle.addEventListener('click', () => {
      const currentTheme = document.documentElement.getAttribute('data-theme');
      const newTheme = currentTheme === 'dark' ? 'light' : 'dark';
      document.documentElement.setAttribute('data-theme', newTheme);
      localStorage.setItem('theme', newTheme);
      themeToggle.innerHTML = newTheme === 'dark' ? '<span class="material-icons-outlined">light_mode</span>' : '<span class="material-icons-outlined">dark_mode</span>';
  });

  // Check for saved theme preference
  const savedTheme = localStorage.getItem('theme') || 'dark';
  document.documentElement.setAttribute('data-theme', savedTheme);
  themeToggle.innerHTML = savedTheme === 'dark' ? '<span class="material-icons-outlined">light_mode</span>' : '<span class="material-icons-outlined">dark_mode</span>';

  document.body.appendChild(themeToggle);
</script>

</body>
</html>